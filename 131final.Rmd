---
title: "final"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(corrplot)
library(klaR)
library(glmnet)
tidymodels_prefer()
library(janitor)
library(xgboost)
library(rpart.plot)
library(ranger)
library(vip)
library(pROC)
library("rpart.plot")
set.seed(4167)
```

## R Markdown

The data set has 297 observations with 14 variables. Target is the response variable, with the other 13 variables predictors.

1. Age - age in years

2. Sex - (1 = male; 0 = female)

3. CP - chest pain type:
Typical angina: chest pain related decrease blood supply to the heart
Atypical angina: chest pain not related to heart
Non-anginal pain: typically esophageal spasms (non heart related)
Asymptomatic: chest pain not showing signs of disease

4. Trestbps - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern

5. Chol - serum cholestoral in mg/dl
serum = LDL + HDL + .2 * triglycerides
above 200 is cause for concern

6. Fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)
'>126' mg/dL signals diabetes

7. Restecg - resting electrocardiographic results
0: Nothing to note
1: ST-T Wave abnormality
can range from mild symptoms to severe problems
signals non-normal heart beat
2.Possible or definite left ventricular hypertrophy
Enlarged heart's main pumping chamber

8. Thalach - maximum heart rate achieved

9. Exang - exercise induced angina (1 = yes; 0 = no)

10. Oldpeak - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more

11. Slope - the slope of the peak exercise ST segment
0: Upsloping: better heart rate with excercise (uncommon)
1: Flatsloping: minimal change (typical healthy heart)
2: Downsloping: signs of unhealthy heart

12. Ca - number of major vessels (0-3) colored by flourosopy
colored vessel means the doctor can see the blood passing through
the more blood movement the better (no clots)

13. Thal - thalium stress result
0: normal 
1: fixed defect: used to be defect but ok now
2: reversable defect: no proper blood movement when exercising

14. Condition - have disease or not (1 = yes, 0 = no) 

```{r}
df <- read_csv("heart_cleveland_upload.csv")
head(df)
```

Cleaning and checking data, then checking if there are missing values; there are not.

```{r}
df <- df %>% clean_names()
head(df)
sum(is.na(df)) 
```

Checking if responsible variable is balanced; since these two values are close to even, our target column can be considered balanced.

```{r}
table(df$condition)
```

Converting `sex`, `cp`, `fbs`, `restecg`, `slope`, `thal`, `condition` to factors.

```{r}
df$sex <- factor(df$sex,
labels = c("Female", "Male"))
df$cp <- factor(df$cp, 
labels = c("Typical angina", "Atypical angina","Non-anginal", "Asymptomatic"))
df$fbs <- factor(df$fbs,
labels = c("Less than 120 mg/dl", "Greater than 120 mg/dl"))                
df$restecg <- factor(df$restecg,
labels = c("Nothing to note", "ST-T wave abnormality", "Possible left ventricular hypertrophy"))                
df$exang <- factor(df$exang,
labels = c('No', 'Yes'))                   
df$slope <- factor(df$slope,
labels = c("Upsloping", "Flatsloping", "Downsloping"))
df$thal <- factor(df$thal,
labels = c("Normal", "Fixed Defect", "Reversible Defect"))
df$condition <- factor(df$condition,
labels = c("No", "Yes"))
head(df)
```


### Data Analysis

This entire exploratory data analysis will be based only on the entire set, which has 297 observations with 14 variables. Each observation represents a single 'df' class.

### Variable age and thalach (max heart rate)
* First, draw a plot of variable `age`.
```{r}
df %>% 
  ggplot(aes(x = age)) +
  geom_bar() 
```

The graph is right skewed, with many respondents between 50-60 and mostly older than 40.

```{r}
df %>% 
  ggplot(aes(x = thalach)) +
  geom_bar() 
```
The graph is right skewed, with many respondents having a max heart rate between 150 and 200.

Draw a graph between age, max heart rate, and condition (green: no, red: yes)
```{r}
plot(df$age, df$thalach, pch = 16, col = c('red', 'green')[df$condition], xlab = "Age", ylab = "Max Heart Rate")
```
Heart condition seems to go down while age goes up (possibly due to a lack of quantity in respondents), heart rate tends to go down with age, and the frequency of a heart condition seems to go up with maximum heart rate.

### Variable sex
Draw a plot of variable `sex`.

```{r}
df %>% 
  ggplot(aes(x = sex)) +
  geom_bar() 
```

According to the graph, we find that there are more observations on 'Male' levels than 'Female' levels for variable `sex`. 

Draw a plot of variable `sex` by `condition` 
```{r}
df %>%
  ggplot(aes(x = sex, y = condition, fill= condition)) +
  geom_bar(stat = "identity")
```

Based on the graph, we see that respondents who are male are more likely to get heart disease. 

### Variable condition (heart disease or not)

* During the process of exploratory data analysis, we first analyze our response variable `condition`. 
```{r}
df %>% 
  ggplot(aes(x = condition)) +
  geom_bar() 
```


* According to the graph, we find that our response variable is almost balanced. Although there are much more observations on 'No' levels than 'Yes' levels, this will not have a significant impact on our predictions.


### Variable trestbps
Now, let's analyze variable `trestbps`.

* First, draw a histogram of variable `trestbps`.
```{r}
hist(df$trestbps, main = paste("Histogram of Resting Blood Pressure"), xlab = 'The value of trestbps', ylab = 'The number of respondents')
```
* The distribution of `trestbps` definitely appears to be left skewed, and it has a long right tail. It also almost looks a normal distribution. Thereâ€™s one peak around 120-130. Most people have a resting blood pressure below 160.


* Second, draw a boxplot of variable `trestbps` by `condition`
```{r}
df %>%
  ggplot(aes(x = trestbps, y= condition))+
  geom_boxplot() +
  xlab("The resting heart rate of the respondent") 
```
Based on the graph, we can find that the respondent who have higher resting heart rate is more likely to get heart disease. 

### Variable chol (cholesterol)
A plot of variable `chol`.
```{r}
df %>% 
  ggplot(aes(x = chol)) +
  geom_bar() 
```
Like 'trestbps', the data is left skewed, with a shorter right tail. Most of the cholesterol levels fall between 200-300 mg/dl, which is above the 200 threshhold for "cause of concern".

### Variable exang (excercise-induced angina)
A plot of variable `exang`.
```{r}
df %>% 
  ggplot(aes(x = exang)) +
  geom_bar() 
```
Draw a plot of variable `exang` by `condition`

```{r}
df %>%
  ggplot(aes(x= exang, y= condition , fill = condition)) +
  geom_bar(stat="identity")+theme_minimal()
```

Based on the graph, we can find that the respondent who have exercise-induced angina are more likely to get heart disease. 


### Variable alcohol_drinking

* First, draw a plot of variable `alcohol_drinking`.
```{r}
newrecords %>% 
  ggplot(aes(x = alcohol_drinking)) +
  geom_bar() 
```

* According to the graph, we find that there are much more observations on 'No' levels than 'Yes' levels for variable alcohol_drinking. For this reason, it maybe hard for us to find the relationship between `alcohol_drinking` and `heart_disease`.


* Second, draw a plot of variable `alcohol_drinking` by `heart_disease` 

```{r}
newrecords %>%
  ggplot(aes(x= alcohol_drinking, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal()
```

* Based on the graph, we can find that the respondent who is not heavy drinker is more likely to get heart disease. [A heavy drinker is a adult men who having more than 14 drinks per week or a adult women who having more than 7 drinks per week ] 
* Notice that the result may not be correct since we have much more observations on 'No' levels than 'Yes' levels for variable alcohol_drinking.  ( We will confirm this result at the end of this project )


### Variable Stroke
* First, draw a plot of variable `stroke`.

```{r}
newrecords %>% 
  ggplot(aes(x = stroke)) +
  geom_bar() 
```

* According to the graph, we find that there are much more observations on 'No' levels than 'Yes' levels for variable `stroke`.For this reason, it maybe hard for us to find the relationship between `stroke` and `heart_disease`.


* Second, draw a plot of variable `stroke` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= stroke, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal()
```

* Based on the graph, we can find that the respondent who had stoke is more likely to get heart disease.( We will confirm this result at the end of this project )


### Variable physical_health

* First, draw a histogram of variable `physical_health`:  The number of days that the respondent had poor physical health in the past 30 days [ Note: It includes physical illness and injury ]
```{r}
hist(newrecords$physical_health, main = paste("Histogram of physical_health"), xlab = 'The number of days that the respondent had poor physical health in the past 30 days', ylab = 'The number of respondents')
```

* According to the graph, we find that most of respondents had less than 10 poor physical health day in the past 30 days, and there are some respondents had 30 poor physical health day in the past 30 days.

* Second, draw a boxplot of variable `physical_health` by `heart_disease`
```{r}
newrecords %>%
  ggplot(aes(x =physical_health , y=heart_disease))+
  geom_boxplot() +
  xlab("The number of days that the respondent had poor physical health in the past 30 days") 
```

* Based on the graph, we can find that the number of days that the respondents had poor physical health in the past 30 days may affect whether they have a heart disease. ( We will confirm this result at the end of this project )





### Variable mental_health

* First, draw a histogram of variable `mental_health`: The number of days that the respondent had poor mental health in the past 30 days 
```{r}
hist(newrecords$mental_health, main = paste("Histogram of mental_health"), xlab = 'The number of days that the respondent had poor mental health in the past 30 days', ylab = 'The number of respondents')
```

* According to the graph, we find that most of respondents had less than 10 poor mental health day in the past 30 days, and there are some respondents had 30 poor mental health days in the past 30 days.

* Second, draw a boxplot of variable `mental_health` by `heart_disease`
```{r}
newrecords %>%
  ggplot(aes(x =mental_health , y=heart_disease))+
  geom_boxplot() +
  xlab("The number of days that the respondent had poor mental health in the past 30 days") 
```

* Based on the graph, we can find that the number of days that the respondents had poor mental health in the past 30 days may affect whether they have a heart disease. ( We will confirm this result at the end of this project )




### Variable diff_walking
* First, draw a plot of variable `diff_walking`.

```{r}
newrecords %>% 
  ggplot(aes(x = diff_walking)) +
  geom_bar() 
```

* According to the graph, we find that there are much more observations on 'No' levels than 'Yes' levels for variable `diff_walking`.For this reason, it maybe hard for us to find the relationship between `diff_walking` and `heart_disease`.

* Second, draw a plot of variable `diff_walking` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= diff_walking, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal()
```

* Based on the graph, we can find that the respondent who has serious difficulty walking or climbing stairs is more likely to get heart disease. ( We will confirm this result at the end of this project )






### Variable race
* First, draw a plot of variable `race`.
```{r}
newrecords %>% 
  ggplot(aes(x = race)) +
  geom_bar() 
```

* According to the graph, we find that most of the respondents are white.  For this reason, it maybe hard for us to find the relationship between `race`` and `heart_disease`.
* Second, draw a plot of variable `race` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= race, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal() 
```

* Based on the graph, although it is difficult for us to tell which race is more likely to heart disease, we can find that the probability of heart disease of different races is not the same. ( We will confirm this result at the end of this project )


### Variable diabetic
* First, draw a plot of variable `diabetic`.
```{r}
newrecords %>% 
  ggplot(aes(x = diabetic)) +
  geom_bar() 
```

* According to the graph, we find that most of the respondents are on level 'No', and some of the respondents are on level 'Yes'.  For this reason, it maybe hard for us to find the relationship between `diabetic` and `heart_disease`.


* Second, draw a plot of variable `diabetic` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= diabetic, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal() 
```

* Based on the graph, we can find that the respondent who had diabetic is more likely to get heart disease.  ( We will confirm this result at the end of this project )


```{r}
head(newrecords)
```

### Variable physical_activity
* First, draw a plot of variable `physical_activity`.  `physical_activity`:  Whether the respondent did physical activity or exercise during the past 30 days other than their regular job.


```{r}
newrecords %>% 
  ggplot(aes(x = physical_activity)) +
  geom_bar() 
```

* According to the graph, we find that most of the respondents are on level 'Yes', and some of the respondents are on level 'No'.  For this reason, it maybe hard for us to find the relationship between `physical_activity` and `heart_disease`.


* Second, draw a plot of variable `physical_activity` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= physical_activity, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal() 
```

* Based on the graph, we can find that the respondent who didn't do physical activity or exercise during the past 30 days other than their regular job is more likely to get heart disease.  ( We will confirm this result at the end of this project )


### Variable gen_health
* First, draw a plot of variable `gen_health`.  `gen_health`: The respondentâ€™s health assessment of his/her self in general [ Notes : the answer should be â€˜Very goodâ€™, â€˜Goodâ€™, â€˜Excellentâ€™, â€˜Fairâ€™, â€˜Poorâ€™ ]

```{r}
newrecords %>% 
  ggplot(aes(x = gen_health)) +
  geom_bar() 
```

* According to the plot, we can see that most of respondents think they are in good and above health, and there are some respondents think they are in fair or poor health.



* Second, draw a plot of variable `gen_health` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= gen_health, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal() 
```

* Based on the graph, we can find that the respondent who think he/she are in poor health is more likely to get heart disease.  ( We will confirm this result at the end of this project )


### Variable sleep_time

* First, draw a histogram of variable `sleep_time`
```{r}
hist(newrecords$sleep_time, main = paste("Histogram ofsleep time "), xlab = 'The number of hours of sleep of the respondent in a 24-hour period', ylab = 'The number of respondents')
```

* According to the graph, we know that the distribution of `sleep_time` definitely appears to be left skewed, and it has a long right tail. It also almost looks a normal distribution. Thereâ€™s one peak around 7-8 hour. Most people have a sleep time between 5- 8 hour. 


* Second, draw a boxplot of variable `sleep_time` by `heart_disease`
```{r}
newrecords %>%
  ggplot(aes(x = sleep_time, y=heart_disease))+
  geom_boxplot() +
  xlab("The number of hours of sleep of the respondent in a 24-hour period") 
```

* From the graph we got, since the boxplots of the two levels ('Yes', 'No') are very similar and the medians are very close to each other, it is very hard for us to tell whether the length of the sleep time is related to heart disease or not. We will explore it more at the modeling part.



### Variable asthma

* First, draw a plot of variable asthma

```{r}
newrecords %>% 
  ggplot(aes(x = asthma)) +
  geom_bar() 
```


* According to the graph, we find that there are much more observations on 'No' levels than 'Yes' levels for variable `asthma`.For this reason, it maybe hard for us to find the relationship between `asthma` and `heart_disease`.

* Second, draw a plot of variable `asthma` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= asthma, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal()
```
* Based on the graph, we can find that the respondent who had asthma is more likely to get heart disease.  ( We will confirm this result at the end of this project )


### Variable kidney_disease

* First, draw a plot of variable kidney_disease
```{r}
newrecords %>% 
  ggplot(aes(x = kidney_disease)) +
  geom_bar() 
```

* According to the graph, we find that there are much more observations on 'No' levels than 'Yes' levels for variable `kidney_disease`.For this reason, it maybe hard for us to find the relationship between `kidney_disease` and `heart_disease`.

* Second, draw a plot of variable `kidney_disease` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= kidney_disease, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal()
```
* Based on the graph, we can find that the respondent who had kidney_disease is more likely to get heart disease.  ( We will confirm this result at the end of this project )



### Variable skin_cancer

* First, draw a plot of variable skin_cancer

```{r}
newrecords %>% 
  ggplot(aes(x = skin_cancer)) +
  geom_bar() 
```

* According to the graph, we find that there are much more observations on 'No' levels than 'Yes' levels for variable `skin_cancer`.For this reason, it maybe hard for us to find the relationship between `skin_cancer` and `heart_disease`.

* Second, draw a plot of variable `skin_cancer` by `heart_disease` 
```{r}
newrecords %>%
  ggplot(aes(x= skin_cancer, y= heart_disease , fill= heart_disease)) +
  geom_bar(stat="identity")+theme_minimal()
```

* Based on the graph, we can find that the respondent who had skin_cancer is more likely to get heart disease.  ( We will confirm this result at the end of this project )


We completed the process of exploratory data analysis.


## Data Split
The data was split in a 80% training, 20% testing split. Stratified sampling was used as the `heart_disease` distribution was skewed. (See more on that in the EDA).

The data split was conducted prior to the EDA as I did not want to know anything about my testing data set before I tested my model on those observations.

```{r}
set.seed(1234)
newrecords_split <- newrecords %>% 
  initial_split(prop = 0.8, strata = "heart_disease")
newrecords_train <- training(newrecords_split)
newrecords_test <- testing(newrecords_split)
```


```{r}
# check whether the training and testing data sets 
# have the appropriate number of observations. 
dim(newrecords)
dim(newrecords_train)
dim(newrecords_test) 
```


* The training data set has about $54760 *0.80$ = 43808 observations and the testing data set has just under $54760*0.20$ =  10952  observations. So, according to what we got from the code and our calculations, we can conclude that our training and testing data sets have the appropriate number of observations. 

## Model Fitting

In this part, I decided to use 4 different model classes (6 models in total).

* Class 1: Logistic regression, LDA and QDA

* Class 2: Boosted tree

* Class 3: Random forest

* Class 4: Nearest Neighbors



### Building the Recipe 
* Using the training data, create a recipe predicting the outcome variable heart_disease.  Include the following predictors:bmi,smoking,alcohol_drinking,stroke,physical_health,  mental_health, diff_walking, sex, age_category,race,diabetic, physical_activity,gen_health  ,sleep_time,asthma, kidney_disease,skin_cancer
* Dummy-code `smoking`, `alcohol_drinking`,`stroke`,`diff_walking`, `sex`, `age_category`, `race`, `diabetic`, `physical_activity`, `gen_health`, `asthma`,`kidney_disease`, `skin_cancer`;
(According to the lecture, we should encode all nominal predictors.)
* Center and scale all predictors.

```{r}
recipe <- recipe(
  heart_disease ~ smoking+ alcohol_drinking+ stroke,physical_health+ mental_health+diff_walking+sex+age_category+race+diabetic+physical_activity+gen_health+sleep_time+asthma+kidney_disease+skin_cancer, data = newrecords_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>% 
  step_scale(all_predictors())
```


###  Uses cross-validation to fold training set.

* We use v-fold cross-validation on the training set. Use 5 folds.
* We stratify the folds by heart_disease as well.
* Stratifying the folds can be useful since it can makes sure the distribution of a heart_disease  (often the outcome) remains the same across resamples or, in cross-validation, across folds.
```{r}
set.seed(1234)
newrecords_folds <- vfold_cv(data = newrecords_train, v = 5, strata = heart_disease )
```

### Class 1: Logistic regression, LDA and QDA

Since these three models belong to the same model class, we want to select the best model among the three models to represent the best model in this class. We will finally use the four models from 4 different model classes to select the best model of the four model classes as our final model.

#### Logistic regression

We specify a logistic regression model for classification using the "glm" engine. Then create a workflow. After that, we add model and the appropriate recipe (we created before). 

```{r}
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")
log_wkflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(recipe)
```

#### LDA

In a similar process, but this time specify a linear discriminant analysis model for classification using the "MASS" engine.

```{r}
lda_mod <- discrim_linear() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")
lda_wkflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(recipe)
```

#### QDA

In a similar process, but this time specify a quadratic discriminant analysis model for classification using the "MASS" engine.

```{r}
qda_mod <- discrim_quad() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")
qda_wkflow <- workflow() %>% 
  add_model(qda_mod) %>% 
  add_recipe(recipe)
```


#### Assess the performance of each of these three models

* Fit each of the models created before to the folded data.
```{r}
control <- control_resamples(save_pred = TRUE)
log_fit <- fit_resamples(log_wkflow, newrecords_folds,control = control)
lda_fit <- fit_resamples(resamples = newrecords_folds, 
                         lda_wkflow,  
                         control = control)
qda_fit <- fit_resamples(qda_wkflow, resamples = newrecords_folds,
                         control = control)
```

* We will use collect_metrics() to print the mean and standard errors of the performance metric accuracy across all folds for each of the four models.

* We will decide which of the 3 fitted models has performed the best. 

```{r}
collect_metrics(log_fit)
```
```{r}
collect_metrics(lda_fit)
```

```{r}
collect_metrics(qda_fit)
```


Based on the results we get here, we can see that these three models have very similar standard error of the accuracy (and the differences between them are very small). Since the mean accuracy of the Logistic regression equals to the mean accuracy of the LDA and both are higher than the mean accuracy of QDA, we know that logistic regression and LDA are better than QDA. 

Also, we found that Logistic regression and LDA have the same mean and standard error roc_auc. This means that they do a same job. Let's just choose Logistic regression as the best models among these three models. 





* Now that weâ€™ve chosen a model, fit our chosen model to the entire training dataset (not to the folds).

```{r}
log_fit_train <- fit(log_wkflow, newrecords_train)
```

* Finally, with your fitted model, use predict(), bind_cols(), and accuracy() to assess your modelâ€™s performance on the testing data!

```{r}
log_test <- fit(log_wkflow, newrecords_test)
predict(log_test, new_data = newrecords_test, type = "class") %>% 
  bind_cols(newrecords_test %>% select(heart_disease)) %>% 
  accuracy(truth = heart_disease, estimate = .pred_class)
```
#### Confusion matrix, ROC curve and AUC values

* Now, using the testing data, we want to create a confusion matrix and visualize it. Plot an ROC curve and calculate the area under it (AUC).

```{r}
#  create a confusion matrix and visualize it
augment(log_test, new_data = newrecords_test) %>%
  conf_mat(truth = heart_disease, estimate = .pred_class) %>% 
  autoplot(type = "heatmap")
```

```{r}
# Plot roc_curve
augment(log_test, new_data = newrecords_test) %>%
  roc_curve(heart_disease, .pred_Yes) %>%
  autoplot()
```

```{r}
# Calculate AUC
augment(log_test, new_data = newrecords_test) %>%
  roc_auc(heart_disease, .pred_Yes)
```

* Based on the results, we find that although Logistic regression is the best among these 3 models, it is still not good enough. We want to see if there is a model work better than Logistic regression in other model class. 

### Class 2: Random Forest 

* Now, we are going to set up a random forest model and workflow. Use the ranger engine and set importance = "impurity". Tune mtry, trees, and min_n. Using the documentation for rand_forest().

```{r}
rf_spec <- rand_forest(mtry = tune(),trees = tune(), min_n = tune()) %>%
  set_engine("randomForest", importance = TRUE) %>%
  set_mode("classification")
rf_wf <- workflow() %>%
  add_model(rf_spec) %>% 
  add_recipe(recipe)
```

* Since we have 17 predictors, then by the lecture, we know that the range for mtry should not be smaller than 1 or larger than 17. 

* Since our dataset is very large, in order to prevent running for too long, we should set levels = 2, and we set the maximum of number of trees be 1000.

```{r}
# set-up grid 
param_grid_rf <- grid_regular(mtry(range = c(1, 17)),
                           trees(range = c(10, 1000)), 
                           min_n(range = c(1, 10)),
                           levels = 2)
```

* Tune the model and print an autoplot() of the results.
```{r}
tune_res <- tune_grid(
  rf_wf, 
  resamples = newrecords_folds, 
  grid = param_grid_rf, 
  metrics = metric_set(roc_auc)
)
# print result
autoplot(tune_res)
```

* Use collect_metric() and arrange() to find what is the roc_auc of my best_performing random forest model on the folds.
```{r}
arrange(collect_metrics(tune_res), desc(mean))
```

* We find that the `mean` of roc_auc of my best_performing random forest model on the folds is 0.647 with `mtry` = 1, `trees` = 1000 and `min_n` = 10. 


* Use select_best() to choose the model that has the optimal roc_auc. Then use finalize_workflow(), fit(), and augment() to fit the model to the training set and evaluate its performance on the testing set.

```{r}
best_complexity<- select_best(tune_res, metric= 'roc_auc')
class_forest_final <- finalize_workflow(rf_wf, best_complexity)
class_forest_final_fit <- fit(class_forest_final, data = newrecords_train)
augment(class_forest_final_fit, new_data = newrecords_test) %>%
  accuracy(truth = heart_disease, estimate = .pred_class)
```



* We want to create and visualize a confusion matrix heat map.
```{r}
augment(class_forest_final_fit, new_data = newrecords_test) %>%
  conf_mat(truth = heart_disease , estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

* Print the ROC curves
```{r}
# Plot roc_curve
augment(class_forest_final_fit, new_data = newrecords_test) %>%
  roc_curve(heart_disease, .pred_Yes) %>%
  autoplot()
```



*  Calculate the AUC value of your best-performing model on the testing set
```{r}
# Calculate AUC
augment(class_forest_final_fit, new_data = newrecords_test) %>%
  roc_auc(heart_disease, .pred_Yes)
```
* Finally, we see that the AUC value of your best-performing model on the testing set is 0.633.

### Class 3 : Boosted tree

* Now, we are going to set up a boosted tree model and workflow. Use the xgboost engine. We will tune mtry, trees, and min_n. Using the documentation for boost_tree().

```{r}
boost_tree_spec <- boost_tree(trees = tune(),
                              min_n = tune(),
                              mtry = tune()
                              ) %>%
  set_engine("xgboost") %>%
  set_mode("classification")
boost_tree_workflow <- workflow() %>% 
  add_model(boost_tree_spec) %>% 
  add_recipe(recipe)
```

* Since we have 17 predictors, then by the lecture, we know that the range for mtry should not be smaller than 1 or larger than 17. 

* Since our dataset is very large, in order to prevent running for too long, we should set levels = 2, and we set the maximum of number of trees be 2000.

```{r}
# set-up grid 
boost_tree_grid<- grid_regular(mtry(range = c(1, 17)),
                           trees(range = c(10, 2000)), 
                           min_n(range = c(1, 10)),
                           levels = 2)
```


* Tune the model and print an autoplot() of the results.
```{r}
boost_tune_res <- tune_grid(
  boost_tree_workflow, 
  resamples = newrecords_folds, 
  grid = boost_tree_grid, 
  metrics = metric_set(roc_auc),
)
autoplot(boost_tune_res)
```

* Use collect_metric() and arrange() to find what is the roc_auc of my best_performing boosted tree model on the folds.
```{r}
arrange(collect_metrics(boost_tune_res), desc(mean))
```

* We find that the `mean` of roc_auc of my best_performing boosted tree model on the folds is 0.651 with `mtry` = 1, `trees` = 10 and `min_n` = 10. 


* Use select_best() to choose the model that has the optimal roc_auc. Then use finalize_workflow(), fit(), and augment() to fit the model to the training set and evaluate its performance on the testing set.


```{r}
best_boost_complexity<- select_best(boost_tune_res, metric= 'roc_auc')
boost_tree_final <- finalize_workflow( boost_tree_workflow, best_boost_complexity)
boost_tree_final_fit  <- fit(boost_tree_final, data = newrecords_train)
# evaluate its performance on the testing set (estimate the accuracy)
augment(boost_tree_final_fit , new_data = newrecords_test) %>%
  accuracy(truth = heart_disease, estimate = .pred_class)
```


* We want to create and visualize a confusion matrix heat map.

```{r}
augment(boost_tree_final_fit, new_data = newrecords_test) %>%
  conf_mat(truth = heart_disease , estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

* Print the ROC curves
```{r}
# Plot roc_curve
augment(boost_tree_final_fit, new_data = newrecords_test) %>%
  roc_curve(heart_disease, .pred_Yes) %>%
  autoplot()
```




*  Calculate the AUC value of your best-performing model on the testing set
```{r}
# Calculate AUC
augment(boost_tree_final_fit , new_data = newrecords_test) %>%
  roc_auc(heart_disease, .pred_Yes)
```
* Finally, we see that the AUC value of your best-performing model on the testing set is 0.646.

### Class 4: K Nearest Neighbors

Lastly, I ran repeated cross fold validation on the K Nearest Neighbor model in the same fashion as the previous two models. For nearest neighbor, I tuned only neighbors as the modelâ€™s other defaults are fine, as mentioned in lab 07. I also set the workflow and added the recipe.

```{r}
knn_model <- nearest_neighbor(neighbors = tune(),mode = "classification") %>%
                              set_engine("kknn")
  
knn_workflow <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(recipe)
```

* I set up a tuning grid and defined it.
```{r}
# set-up tuning grid 
knn_params <- parameters(knn_model)
# define grid
knn_grid <- grid_regular(knn_params, levels = 2)
```


* Tune the model and print an autoplot() of the results.
```{r}
knn_tune <- knn_workflow %>% 
  tune_grid(resamples = newrecords_folds, 
            grid = knn_grid,
            metrics = metric_set(roc_auc))
autoplot(knn_tune)
```

* Use collect_metric() and arrange() to find what is the roc_auc of my best_performing KNN model on the folds.
```{r}
arrange(collect_metrics(knn_tune),desc(mean))
```

* We find that the `mean` of roc_auc of my best_performing boosted tree model on the folds is 0.501 with `neighbors` = 15


* Use select_best() to choose the model that has the optimal roc_auc. Then use finalize_workflow(), fit(), and augment() to fit the model to the training set and evaluate its performance on the testing set.


```{r}
best_knn_complexity<- select_best(knn_tune, metric= 'roc_auc')
knn_final <- finalize_workflow( knn_workflow, best_knn_complexity)
knn_final_fit  <- fit(knn_final, data = newrecords_train)
# evaluate its performance on the testing set (estimate the accuracy)
augment(knn_final_fit , new_data = newrecords_test) %>%
  accuracy(truth = heart_disease, estimate = .pred_class)
```


* We want to create and visualize a confusion matrix heat map.
```{r}
# create and visualize a confusion matrix heat map.
augment(knn_final_fit, new_data = newrecords_test) %>%
  conf_mat(truth = heart_disease , estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```


* Print the ROC curves
```{r}
# Plot roc_curve
augment(knn_final_fit, new_data = newrecords_test) %>%
  roc_curve(heart_disease, .pred_Yes) %>%
  autoplot()
```


*  Calculate the AUC value of your best-performing model on the testing set

```{r}
# Calculate AUC
augment(knn_final_fit , new_data = newrecords_test) %>%
  roc_auc(heart_disease, .pred_Yes)
```
### Final model 

* In this project, we have tried four different model types. Now let's compare the AUC and accuracy values of these four types of models on the testing set and select our final model. (Recall: Logistic regression is the best model among Logistic regression, LDA and QDA models. We won't show LDA and QDA here since Logistic regression, LDA and QDA come from same model class.)

```{r}
# create a matrix that contains the accuracy and AUC 
# from Model Logistic regression, Random Forest, Boosted tree, KNN
Model_Name <-c('Logistic regression', 'Random Forest', 'Boosted tree', 'KNN')
Accuracy <- c(0.622,0.622,0.622,0.500)
AUC <- c( 0.646,0.645,0.643,0.501)
information <- cbind(Model_Name,Accuracy,AUC)
# convert it to a tibble
as_tibble(information) 
```

* Based on report we got above, we can see that Logistic regression is the best model in all these 4 different models since it has both highest accuracy and highest AUC values. 


```{r}
# assignment log_test to final_model
final_model <- log_test
```
* In all these 17 key indicators, `stroke` is the most important variable to our model.In other words, people who have had a stroke are more likely to have heart disease.


### Letâ€™s Check A Few Predictions

In order to show you how our model exactly work, let's use 2 examples to predict whether people will get heart disease or not based on some key indicators.

* Set up example 1, and do a prediction
```{r}
# set up example 1 
qualification1 <- data.frame(
  bmi = 24,
  smoking = 'No',
  alcohol_drinking = 'No',
  stroke = 'No',
  physical_health = 0,
  mental_health = 4,
  diff_walking = 'No',
  sex = 'Male',
  age_category = '18-24',
  race = 'Asian',
  diabetic = 'No',
  physical_activity = 'Yes',
  gen_health  ='Excellent',
  sleep_time = 9,
  asthma = 'No',
  kidney_disease = 'No',
  skin_cancer = 'No'
) %>% 
mutate(
    #heart_disease  = factor(heart_disease, levels = c('Yes', 'No')),
    smoking  = factor(smoking, levels = c('Yes', 'No')),
    alcohol_drinking  = factor(alcohol_drinking, levels = c('Yes', 'No')),
    stroke  = factor(stroke, levels = c('Yes', 'No')),
    diff_walking  = factor(diff_walking, levels = c('Yes', 'No')),
    sex  = factor(sex),
    age_category  = factor(age_category),
    race  = factor(race, levels = c("American Indian/Alaskan Native", "Asian", "Black", "Hispanic", "White", "Other")),
    diabetic  = factor(diabetic, levels = c("No", "No, borderline diabetes", "Yes", "Yes (during pregnancy)")),
    physical_activity  = factor(physical_activity),
    gen_health  = factor(gen_health, levels = c("Excellent","Very good", "Good", "Fair", "Poor" )),
    asthma  = factor(asthma, levels = c('Yes', 'No')),
    kidney_disease  = factor(kidney_disease, levels = c('Yes', 'No')),
    skin_cancer  = factor(skin_cancer, levels = c('Yes', 'No')),
  )
```

```{r}
# do a prediction
predict(final_model, qualification1)
```


* Set up example 2, and do a prediction
```{r}
# set up example 2
qualification2 <- data.frame(
  bmi = 40,
  smoking = 'Yes',
  alcohol_drinking = 'Yes',
  stroke = 'Yes',
  physical_health = 30,
  mental_health = 30,
  diff_walking = 'Yes',
  sex = 'Female',
  age_category = '75-79',
  race = 'Asian',
  diabetic = 'Yes',
  physical_activity = 'No',
  gen_health  ='Poor',
  sleep_time = 6,
  asthma = 'Yes',
  kidney_disease = 'Yes',
  skin_cancer = 'Yes'
) %>% 
mutate(
    smoking  = factor(smoking, levels = c('Yes', 'No')),
    alcohol_drinking  = factor(alcohol_drinking, levels = c('Yes', 'No')),
    stroke  = factor(stroke, levels = c('Yes', 'No')),
    diff_walking  = factor(diff_walking, levels = c('Yes', 'No')),
    sex  = factor(sex),
    age_category  = factor(age_category),
    race  = factor(race, levels = c("American Indian/Alaskan Native", "Asian", "Black", "Hispanic", "White", "Other")),
    diabetic  = factor(diabetic, levels = c("No", "No, borderline diabetes", "Yes", "Yes (during pregnancy)")),
    physical_activity  = factor(physical_activity),
    gen_health  = factor(gen_health, levels = c("Excellent","Very good", "Good", "Fair", "Poor" )),
    asthma  = factor(asthma, levels = c('Yes', 'No')),
    kidney_disease  = factor(kidney_disease, levels = c('Yes', 'No')),
    skin_cancer  = factor(skin_cancer, levels = c('Yes', 'No')),
  )
```

```{r}
# do a prediction
predict(final_model, qualification2)
```

## Conclusion



